# TalentScout AI â€“ Smart Hiring Assistant

An interactive Streamlit app that screens candidates, collects basic info, and **auto-generates technical questions** based on the candidateâ€™s tech stack using Googleâ€™s Generative AI via LangChain.

[![Watch on YouTube](https://github.com/SudeshRPatil20/TalentScout-AI-Smart-Hiring-Assistant/blob/main/images/Screenshot%20(733).png)](https://www.youtube.com/watch?v=Yz4ee15U9Sw)

> Click the thumbnail to watch the demo on YouTube.

---

## âœ¨ Features

- ğŸ“‹ Guided candidate intake (name, email, experience, role, location)
- ğŸ§  LLM-powered question generation tailored to a provided tech stack
- âš™ï¸ Configurable model, temperature, and token limits from the sidebar
- ğŸ” `.env`-based key management
- ğŸ§© Built with Streamlit + LangChain + Google Generative AI

---

## ğŸ§° Tech Stack

- **Python**, **Streamlit**
- **LangChain** (`langchain_core`, `langchain_google_genai`)
- **Google Generative AI** (`google-generativeai`)
- **python-dotenv** for environment variables

---

## ğŸš€ Quick Start

### 1) Clone & Install
```bash
git clone https://github.com/<your-username>/talentscout-ai.git
cd talentscout-ai
pip install -r requirements.txt


requirements.txt

streamlit
python-dotenv
google-generativeai
langchain
langchain-core
langchain-google-genai

2) Set Environment Variables

Create a .env file in the project root:

LANGCHAIN_API_KEY=your_langchain_api_key_optional
GOOGLE_API_KEY=your_google_genai_api_key


The app reads GOOGLE_API_KEY via dotenv for google.generativeai.
LANGCHAIN_API_KEY is optional and only used if you want LangSmith tracing.

3) Run the App
streamlit run app.py


Open the URL Streamlit prints (usually http://localhost:8501).

ğŸ–¥ï¸ Usage

In the sidebar, paste your Google GenAI API key (or rely on .env).

Select a model (e.g. gemini-1.5-flash-8b-latest) and adjust temperature / max tokens.

Fill in the candidate details on the main screen and click Next â¡ï¸.

Enter the candidateâ€™s tech stack and click Generate Questions.

Review the generated questions shown by the app.

ğŸ§© Code Overview

app.py â€” Streamlit UI and chat flow (intro â†’ tech stack â†’ questions â†’ conclude)

Uses a ChatPromptTemplate to ask the LLM for 3â€“5 technical questions:

question_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful hiring assistant. Ask 3 to 5 technical questions based on the tech stack provided."),
    ("user", "Tech Stack: {tech_stack}")
])


LLM wrapper:

llm = ChatGoogleGenerativeAI(model=model_name)
result = (question_prompt | llm | StrOutputParser()).invoke({"tech_stack": tech_stack})

ğŸ” Notes on API Keys

You can set GOOGLE_API_KEY in .env or paste it into the sidebar.

Never commit your .env fileâ€”add it to .gitignore.

ğŸ§ª Troubleshooting

ModuleNotFoundError: Ensure all packages are installed from requirements.txt.

Key/Quota errors: Verify GOOGLE_API_KEY is valid and has access to the selected model.

Nothing happens on click: Check the terminal logs where Streamlit is running for exceptions.

ğŸ—ºï¸ Roadmap

 Persist candidate responses to a database (e.g., SQLite / Postgres)

 Export questions & candidate info as PDF

 Add role-specific prompt templates and evaluation rubrics

 Multi-turn follow-ups based on candidate answers

ğŸ“œ License

MIT â€” feel free to use and adapt.

ğŸ™Œ Acknowledgements

Streamlit

LangChain

Google Generative AI
